{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST HALF OF THIS NOTEBOOK IS FOR NUCLEAR NORM IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import numpy as np\n",
    "\n",
    "# # read google spreadsheet data saved as csv\n",
    "# df = pd.read_csv(\"original_data.csv\")\n",
    "\n",
    "# # define actuator class names\n",
    "# classes = [\"PZT\", \"DEA\", \"IPMC\", \"SMA\", \"SCP\", \"SFA\", \"TSA\", \"EAP\"]\n",
    "\n",
    "# # delete first column from dataframe\n",
    "# df = df.drop('Reference', axis=1)\n",
    "\n",
    "# # define new first column as labels for actuator type\n",
    "# actuator_type = df['Actuator Type']\n",
    "\n",
    "# # extract actuator type and set as label\n",
    "# lbl = [] \n",
    "\n",
    "# # remove SMP actuator types\n",
    "# df = df[df['Actuator Type'] != 'SMP']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actuator Type</th>\n",
       "      <th>Bandwidth (Hz)</th>\n",
       "      <th>Strain (%)</th>\n",
       "      <th>Stress (MPa)</th>\n",
       "      <th>Efficiency (%)</th>\n",
       "      <th>Power Density (W/g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PZT</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>110.0000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PZT</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEA</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IPMC</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>200.0000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>SMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.245786</td>\n",
       "      <td>502.7902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>SMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.290964</td>\n",
       "      <td>515.8417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>SMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.330979</td>\n",
       "      <td>534.8862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>SMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.327107</td>\n",
       "      <td>525.1642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>SMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.318071</td>\n",
       "      <td>520.0368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actuator Type  Bandwidth (Hz)  Strain (%)  Stress (MPa)  Efficiency (%)  \\\n",
       "0             PZT         10000.0    0.200000      110.0000            90.0   \n",
       "1             PZT           100.0         NaN           NaN            90.0   \n",
       "2             DEA           100.0  200.000000        8.0000            85.0   \n",
       "3            IPMC            10.0   40.000000        0.3000             NaN   \n",
       "4             SMA             3.0    5.000000      200.0000             1.3   \n",
       "..            ...             ...         ...           ...             ...   \n",
       "673           SMA             NaN    2.245786      502.7902             NaN   \n",
       "674           SMA             NaN    2.290964      515.8417             NaN   \n",
       "675           SMA             NaN    2.330979      534.8862             NaN   \n",
       "676           SMA             NaN    2.327107      525.1642             NaN   \n",
       "677           SMA             NaN    2.318071      520.0368             NaN   \n",
       "\n",
       "     Power Density (W/g)  \n",
       "0                   0.20  \n",
       "1                    NaN  \n",
       "2                   0.20  \n",
       "3                   0.02  \n",
       "4                  50.00  \n",
       "..                   ...  \n",
       "673                  NaN  \n",
       "674                  NaN  \n",
       "675                  NaN  \n",
       "676                  NaN  \n",
       "677                  NaN  \n",
       "\n",
       "[647 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8661417322834646\n",
      "0.8831168831168831\n",
      "0.6896551724137931\n",
      "0.6153846153846154\n",
      "0.8661417322834646\n",
      "0.8968253968253969\n",
      "0.889763779527559\n",
      "0.872\n",
      "0.935064935064935\n",
      "0.8809523809523809\n",
      "0.8831168831168831\n",
      "0.84\n",
      "0.6206896551724138\n",
      "0.84251968503937\n",
      "0.8571428571428571\n",
      "0.72\n",
      "0.6538461538461539\n",
      "0.88\n",
      "0.88\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "# from matrix_completion import *\n",
    "# import sklearn\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import figure\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import figure\n",
    "# import matplotlib.cm as cm\n",
    "# import pickle \n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# actuator_typ = 'Actuator Type'\n",
    "# df1 = df\n",
    "# df1 = df1.drop('Actuator Type', axis=1)\n",
    "# for (col1_name, col1_data) in df1.iteritems(): \n",
    "#     for (col2_name, col2_data) in df1.iteritems():\n",
    "#         if col1_name == col2_name:\n",
    "#             continue\n",
    "#         #print('Column 1:', col1_name)\n",
    "#         #print('Column 2:', col2_name)\n",
    "#         #numeric = [col1_name, col2_name]\n",
    "#         #create temp dataframe with current two features + actuator type\n",
    "#         df_temp = df[[actuator_typ, col1_name, col2_name]]\n",
    "#         #drop entire row if both features are NaN\n",
    "#         df_temp = df_temp.dropna(subset=[col1_name, col2_name], how='all')\n",
    "#         #print(col1_name, col2_name, len(df_temp))\n",
    "        \n",
    "        \n",
    "#         lbl.clear()\n",
    "\n",
    "#         # create labels for classes\n",
    "#         for index, row in df_temp.iterrows():\n",
    "#             for i, classification in enumerate(classes):\n",
    "#                 if row[\"Actuator Type\"] == classification:\n",
    "#                     lbl.append(i)\n",
    "\n",
    "\n",
    "#         # drop first column now that we have labels \n",
    "#         df_temp = df_temp.drop('Actuator Type', axis=1)\n",
    "        \n",
    "#         # convert all values in columns to numeric type\n",
    "#         df_temp = df_temp[[col1_name, col2_name]].apply(pd.to_numeric)\n",
    "#         df_temp = df_temp.apply(pd.to_numeric)\n",
    "        \n",
    "        \n",
    "#         # casts everything to float and numpy matrix\n",
    "#         df_numeric = df_temp.to_numpy()\n",
    "\n",
    "\n",
    "#         shape = df_numeric.shape\n",
    "\n",
    "\n",
    "#         mask = np.ones((shape[0], shape[1]))\n",
    "\n",
    "#         # set missing values to 0\n",
    "#         mask[np.isnan(df_numeric)] = 0\n",
    "\n",
    "#         imputed = nuclear_norm_solve(df_numeric, mask)      \n",
    "\n",
    "#         # transforming numpy array to dataframe and setting columsn and indicies\n",
    "#         df_imputed = pd.DataFrame(imputed)\n",
    "#         df_imputed.columns = df_temp.columns\n",
    "#         df_imputed.index = df_temp.index\n",
    "\n",
    "#         df_imputed = df_imputed.apply(np.log)\n",
    "        \n",
    "#         # remove non-numeric values  columns\n",
    "#         df_imputed[col1_name] = pd.to_numeric(df_imputed[col1_name], errors='coerce')\n",
    "#         df_imputed[col2_name] = pd.to_numeric(df_imputed[col2_name], errors='coerce')\n",
    "        \n",
    "#         actuator_type = []\n",
    "\n",
    "#         # iterate through labels and find corresponding actuator type\n",
    "#         for i, act_type in enumerate(lbl):\n",
    "#             for j, classif in enumerate(classes):\n",
    "#                 if act_type == j: \n",
    "#                     actuator_type.append(classes[j])\n",
    "\n",
    "#         # add a column to df_plt for actuator type \n",
    "#         df_imputed['Actuator Type'] = actuator_type\n",
    "        \n",
    "#         df_imputed = df_imputed.dropna()\n",
    "        \n",
    "#         lbl.clear()\n",
    "\n",
    "#         # create labels for classes\n",
    "#         for index, row in df_imputed.iterrows():\n",
    "#             for i, classification in enumerate(classes):\n",
    "#                 if row[\"Actuator Type\"] == classification:\n",
    "#                     lbl.append(i)\n",
    "\n",
    "\n",
    "#         # drop first column now that we have labels \n",
    "#         df_imputed = df_imputed.drop('Actuator Type', axis=1)\n",
    "\n",
    "#         # change df to numpy array\n",
    "#         df_np = df_imputed.to_numpy()\n",
    "        \n",
    "#         scaler = StandardScaler()\n",
    "#         # scales data by removing mean and scaling to the variance\n",
    "#         scaler.fit(df_np)\n",
    "\n",
    "#         # applies scaler to dataset \n",
    "#         x = scaler.transform(df_np)\n",
    "\n",
    "#         # casts list of labels as numpy array\n",
    "#         y = np.array(lbl) \n",
    "\n",
    "#         # split data into train and test set\n",
    "#         x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .2)\n",
    "        \n",
    "#         # set up classifier\n",
    "#         clf = SVC(kernel = 'rbf', C=1000, probability=True)\n",
    "\n",
    "#         # train training data set \n",
    "#         clf.fit(x_train, y_train)\n",
    "        \n",
    "#         y_test_predict = clf.predict(x_test)\n",
    "#         y_test_prob = clf.predict_proba(x_test)\n",
    "#         y_train_predict = clf.predict(x_train)\n",
    "#         y_train_prob = clf.predict_proba(x_train)\n",
    "\n",
    "#         sklearn.metrics.accuracy_score(y_test_predict, y_test)\n",
    "        \n",
    "#         sklearn.metrics.accuracy_score(y_train_predict, y_train)\n",
    "        \n",
    "#         #both preds and truths are same shape m by n (m is number of predictions and n is number of classes)\n",
    "#         def top_n_accuracy(preds, truths, n):\n",
    "#             best_n = np.argsort(preds, axis=1)[:,-n:]\n",
    "#             ts = truths\n",
    "#             successes = 0\n",
    "#             for i in range(ts.shape[0]):\n",
    "#               if ts[i] in best_n[i,:]:\n",
    "#                 successes += 1\n",
    "#             return float(successes)/ts.shape[0]\n",
    "        \n",
    "#         #print(col1_name, col2_name, len(df_np))\n",
    "#         #print('test: ' + str(top_n_accuracy(y_test_prob, y_test, 3)))\n",
    "#         print(top_n_accuracy(y_test_prob, y_test, 3))\n",
    "#         #print('train: ' + str(top_n_accuracy(y_train_prob, y_train, 3)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FOLLOWING IS FOR NO IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# read google spreadsheet data saved as csv\n",
    "df = pd.read_csv(\"original_data.csv\")\n",
    "\n",
    "# define actuator class names\n",
    "classes = [\"PZT\", \"DEA\", \"IPMC\", \"SMA\", \"SCP\", \"SFA\", \"TSA\", \"EAP\"]\n",
    "\n",
    "# delete first column from dataframe\n",
    "df = df.drop('Reference', axis=1)\n",
    "\n",
    "# define new first column as labels for actuator type\n",
    "actuator_type = df['Actuator Type']\n",
    "\n",
    "# extract actuator type and set as label\n",
    "lbl = [] \n",
    "\n",
    "# remove SMP actuator types\n",
    "df = df[df['Actuator Type'] != 'SMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use if NO IMPUTATION is required !\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actuator Type          0\n",
       "Bandwidth (Hz)         0\n",
       "Strain (%)             0\n",
       "Stress (MPa)           0\n",
       "Efficiency (%)         0\n",
       "Power Density (W/g)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from matrix_completion import *\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.cm as cm\n",
    "import pickle \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "actuator_typ = 'Actuator Type'\n",
    "df1 = df\n",
    "df1 = df1.drop('Actuator Type', axis=1)\n",
    "\n",
    "for (col1_name, col1_data) in df1.iteritems(): \n",
    "    for (col2_name, col2_data) in df1.iteritems(): \n",
    "        if col1_name == col2_name:\n",
    "            continue\n",
    "        #print('Column 1:', col1_name)\n",
    "        #print('Column 2:', col2_name)\n",
    "        #numeric = [col1_name, col2_name]\n",
    "        df_temp = df[[actuator_typ, col1_name, col2_name]]\n",
    "        \n",
    "        df_temp = df_temp.dropna()\n",
    "        \n",
    "        lbl.clear()\n",
    "\n",
    "        for index, row in df_temp.iterrows():\n",
    "            for i, classification in enumerate(classes):\n",
    "                if row[\"Actuator Type\"] == classification:\n",
    "                    lbl.append(i)\n",
    "\n",
    "        # drop first column now that we have labels \n",
    "        df_temp = df_temp.drop('Actuator Type', axis=1)\n",
    "        \n",
    "        df_temp = df_temp[[col1_name, col2_name]].apply(pd.to_numeric)\n",
    "        df_temp = df_temp.apply(pd.to_numeric)\n",
    "        \n",
    "        df_temp.isnull().sum(axis = 0)\n",
    "        \n",
    "        df_imputed = df_temp\n",
    "\n",
    "        # remove non-numeric values in stress/strain columns\n",
    "        df_imputed[col1_name] = pd.to_numeric(df_imputed[col1_name], errors='coerce')\n",
    "        df_imputed[col2_name] = pd.to_numeric(df_imputed[col2_name], errors='coerce')\n",
    "\n",
    "        # dataframe of stress and strain properties\n",
    "        df_imputed = df_imputed.dropna()\n",
    "\n",
    "        # change df to numpy array\n",
    "        df_np = df_imputed.to_numpy()\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        # scales data by removing mean and scaling to the variance\n",
    "        scaler.fit(df_np)\n",
    "\n",
    "        # applies scaler to dataset \n",
    "        x = scaler.transform(df_np)\n",
    "\n",
    "        # casts list of labels as numpy array\n",
    "        y = np.array(lbl)\n",
    "        \n",
    "        # split data into train and test set\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .2)\n",
    "        \n",
    "        # set up classifier\n",
    "        clf = SVC(kernel = 'rbf', C=1000, probability=True)\n",
    "\n",
    "        # train training data set \n",
    "        clf.fit(x_train, y_train)\n",
    "        \n",
    "        y_test_predict = clf.predict(x_test)\n",
    "        y_test_prob = clf.predict_proba(x_test)\n",
    "        y_train_predict = clf.predict(x_train)\n",
    "        y_train_prob = clf.predict_proba(x_train)\n",
    "\n",
    "        sklearn.metrics.accuracy_score(y_test_predict, y_test)\n",
    "        \n",
    "        sklearn.metrics.accuracy_score(y_train_predict, y_train)\n",
    "        \n",
    "        #both preds and truths are same shape m by n (m is number of predictions and n is number of classes)\n",
    "        def top_n_accuracy(preds, truths, n):\n",
    "            best_n = np.argsort(preds, axis=1)[:,-n:]\n",
    "            ts = truths\n",
    "            successes = 0\n",
    "            for i in range(ts.shape[0]):\n",
    "              if ts[i] in best_n[i,:]:\n",
    "                successes += 1\n",
    "            return float(successes)/ts.shape[0]\n",
    "        \n",
    "        #print(col1_name, col2_name)\n",
    "        #print('test: ' + str(top_n_accuracy(y_test_prob, y_test, 3)))\n",
    "        print(top_n_accuracy(y_test_prob, y_test, 3))\n",
    "        #print('train: ' + str(top_n_accuracy(y_train_prob, y_train, 3)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '1v1.pkl'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
